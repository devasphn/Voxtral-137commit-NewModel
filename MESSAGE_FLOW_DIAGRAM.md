# Message Flow Diagram - Before vs After

## ğŸ”´ BEFORE (Broken - Missing Handlers)

```
Server                                  Client
------                                  ------

[User speaks]
    â†“
process_chunked_streaming()
    â†“
yield token_chunk                   â†’   ws.onmessage
    {                                       â†“
      type: "token_chunk",              handleWebSocketMessage()
      text: "Hello",                        â†“
      chunk_sequence: 1                 switch(data.type)
    }                                       â†“
                                        default:
                                            âŒ Unknown message type: token_chunk
                                            (Token ignored, not displayed)
    â†“
yield semantic_chunk                â†’   ws.onmessage
    {                                       â†“
      type: "semantic_chunk",           handleWebSocketMessage()
      text: "Hello!",                       â†“
      full_text_so_far: "Hello!"        switch(data.type)
    }                                       â†“
                                        default:
                                            âŒ Unknown message type: semantic_chunk
                                            (Word ignored, not displayed)
    â†“
synthesize_speech_streaming()
    â†“
yield audio_chunk                   â†’   ws.onmessage
    {                                       â†“
      type: "sequential_audio",         handleWebSocketMessage()
      audio_data: "UklGRi4...",             â†“
      sample_rate: 24000                switch(data.type)
    }                                       â†“
                                        case 'sequential_audio':
                                            handleSequentialAudio(data)
                                                â†“
                                            audioQueue.push({
                                                chunkId: data.chunk_id,
                                                audioData: data.audio_data,
                                                sampleRate: 24000,
                                                // âŒ No metadata object!
                                            })
                                                â†“
                                            playAudioItem(audioItem)
                                                â†“
                                            audio.addEventListener('canplaythrough', () => {
                                                // âŒ TypeError: Cannot read 'audio_duration_ms' of undefined
                                                log(`${metadata.audio_duration_ms}ms`);
                                            })
    â†“
yield chunked_streaming_complete    â†’   ws.onmessage
    {                                       â†“
      type: "chunked_streaming_complete", handleWebSocketMessage()
      response_text: "Hello! Yes...",       â†“
      total_tokens: 14,                 switch(data.type)
      first_token_latency_ms: 95.3          â†“
    }                                   default:
                                            âŒ Unknown message type: chunked_streaming_complete
                                            (Statistics ignored, not displayed)
                                            âŒ pendingResponse NOT reset!
                                                â†“
                                            [Second interaction blocked]
```

---

## ğŸŸ¢ AFTER (Fixed - All Handlers Working)

```
Server                                  Client
------                                  ------

[User speaks]
    â†“
process_chunked_streaming()
    â†“
yield token_chunk                   â†’   ws.onmessage
    {                                       â†“
      type: "token_chunk",              handleWebSocketMessage()
      text: "Hello",                        â†“
      chunk_sequence: 1,                switch(data.type)
      inter_token_latency_ms: 95.3          â†“
    }                                   case 'token_chunk':
                                            âœ… handleTokenChunk(data)
                                                â†“
                                            log(`ğŸ”¤ Token 1: "Hello" (95.3ms)`)
                                            responseDiv.textContent += "Hello"
                                            updateStatus('ğŸ”„ Streaming response...')
    â†“
yield token_chunk                   â†’   ws.onmessage
    {                                       â†“
      type: "token_chunk",              handleWebSocketMessage()
      text: "!",                            â†“
      chunk_sequence: 2,                switch(data.type)
      inter_token_latency_ms: 42.1          â†“
    }                                   case 'token_chunk':
                                            âœ… handleTokenChunk(data)
                                                â†“
                                            log(`ğŸ”¤ Token 2: "!" (42.1ms)`)
                                            responseDiv.textContent += "!"
    â†“
yield semantic_chunk                â†’   ws.onmessage
    {                                       â†“
      type: "semantic_chunk",           handleWebSocketMessage()
      text: "Hello!",                       â†“
      full_text_so_far: "Hello!",       switch(data.type)
      chunk_sequence: 1,                    â†“
      boundary_type: "word"             case 'semantic_chunk':
    }                                       âœ… handleSemanticChunk(data)
                                                â†“
                                            log(`ğŸ“ Semantic chunk 1: "Hello!" (word)`)
                                            responseDiv.textContent = "Hello!"
                                            updateStatus('ğŸ”„ Streaming: "Hello!"...')
    â†“
synthesize_speech_streaming()
    â†“
yield audio_chunk                   â†’   ws.onmessage
    {                                       â†“
      type: "sequential_audio",         handleWebSocketMessage()
      audio_data: "UklGRi4...",             â†“
      sample_rate: 24000,               switch(data.type)
      chunk_size_bytes: 63644,              â†“
      text_source: "Hello!"             case 'sequential_audio':
    }                                       âœ… handleSequentialAudio(data)
                                                â†“
                                            // âœ… Calculate metadata
                                            const sampleRate = 24000;
                                            const audioDurationMs = (63644 - 44) / (24000 * 2) * 1000;
                                                â†“
                                            audioQueue.push({
                                                chunkId: data.chunk_id,
                                                audioData: data.audio_data,
                                                sampleRate: 24000,
                                                // âœ… Metadata object included!
                                                metadata: {
                                                    audio_duration_ms: 2650,
                                                    sample_rate: 24000,
                                                    chunk_size_bytes: 63644,
                                                    format: 'wav'
                                                }
                                            })
                                                â†“
                                            playAudioItem(audioItem)
                                                â†“
                                            // âœ… Extract metadata and sampleRate
                                            const { metadata = {}, sampleRate = 24000 } = audioItem;
                                                â†“
                                            audio.addEventListener('loadedmetadata', () => {
                                                // âœ… Use sampleRate from audioItem
                                                log(`Sample Rate: ${sampleRate}Hz`);
                                                // Output: "Sample Rate: 24000Hz" âœ…
                                            })
                                                â†“
                                            audio.addEventListener('canplaythrough', () => {
                                                // âœ… Safe access with optional chaining
                                                const durationMs = metadata?.audio_duration_ms || 'unknown';
                                                log(`${durationMs}ms`);
                                                // Output: "2650ms" âœ…
                                            })
                                                â†“
                                            [Audio plays successfully] âœ…
    â†“
yield chunked_streaming_complete    â†’   ws.onmessage
    {                                       â†“
      type: "chunked_streaming_complete", handleWebSocketMessage()
      response_text: "Hello! Yes...",       â†“
      total_tokens: 14,                 switch(data.type)
      total_words: 9,                       â†“
      total_time_ms: 31427.6,           case 'chunked_streaming_complete':
      first_token_latency_ms: 95.3,         âœ… handleStreamingComplete(data)
      first_word_latency_ms: 187.2,             â†“
      first_audio_latency_ms: 289.5         log(`âœ… Streaming complete: "Hello! Yes..."`)
    }                                       log(`   ğŸ“Š Stats: 14 tokens, 9 words in 31427.6ms`)
                                            log(`   âš¡ First token: 95.3ms`)
                                            log(`   ğŸ“ First word: 187.2ms`)
                                            log(`   ğŸ”Š First audio: 289.5ms`)
                                                â†“
                                            responseDiv.textContent = "Hello! Yes..."
                                            updateStatus('âœ… Response complete (31428ms)')
                                                â†“
                                            // âœ… CRITICAL: Reset flag for next interaction
                                            pendingResponse = false;
                                                â†“
                                            [Second interaction ready] âœ…
```

---

## ğŸ“Š Message Type Comparison

| Message Type | Before | After |
|--------------|--------|-------|
| `token_chunk` | âŒ Unknown message type | âœ… Handled by `handleTokenChunk()` |
| `semantic_chunk` | âŒ Unknown message type | âœ… Handled by `handleSemanticChunk()` |
| `sequential_audio` | âš ï¸ Handled but metadata missing | âœ… Handled with complete metadata |
| `chunked_streaming_complete` | âŒ Unknown message type | âœ… Handled by `handleStreamingComplete()` |

---

## ğŸ”„ Second Interaction Flow

### **BEFORE (Blocked):**
```
First Interaction Complete
    â†“
pendingResponse = true (still set from first interaction) âŒ
    â†“
[User speaks again]
    â†“
audioWorkletNode.onaudioprocess = (event) => {
    if (!isStreaming || pendingResponse) return;  // âŒ Returns early!
    // Audio processing blocked
}
    â†“
[No response generated] âŒ
```

### **AFTER (Working):**
```
First Interaction Complete
    â†“
handleStreamingComplete(data)
    â†“
pendingResponse = false;  // âœ… Reset!
    â†“
[User speaks again]
    â†“
audioWorkletNode.onaudioprocess = (event) => {
    if (!isStreaming || pendingResponse) return;  // âœ… Continues!
    // Audio processing continues
    sendAudioChunk(audioData);
}
    â†“
[Response generated successfully] âœ…
```

---

## ğŸ¯ Key Improvements

### **1. Real-Time Token Display**
```
Before: Tokens ignored âŒ
After:  ğŸ”¤ Token 1: "Hello" (95.3ms) âœ…
        ğŸ”¤ Token 2: "!" (42.1ms) âœ…
```

### **2. Real-Time Word Display**
```
Before: Words ignored âŒ
After:  ğŸ“ Semantic chunk 1: "Hello!" (word) âœ…
        ğŸ“ Semantic chunk 2: "Yes, I" (word) âœ…
```

### **3. Proper Audio Metadata**
```
Before: TypeError: Cannot read 'audio_duration_ms' of undefined âŒ
        Sample Rate: unknownHz âŒ
        
After:  Sample Rate: 24000Hz âœ…
        Audio chunk ready to play (2650ms) âœ…
```

### **4. Completion Statistics**
```
Before: Statistics ignored âŒ

After:  âœ… Streaming complete: "Hello! Yes, I can hear you..."
           ğŸ“Š Stats: 14 tokens, 9 words in 31427.6ms
           âš¡ First token: 95.3ms
           ğŸ“ First word: 187.2ms
           ğŸ”Š First audio: 289.5ms âœ…
```

### **5. Multiple Interactions**
```
Before: Second interaction blocked âŒ

After:  First interaction â†’ Complete â†’ pendingResponse = false
        Second interaction â†’ Works perfectly âœ…
        Third interaction â†’ Works perfectly âœ…
```

---

## âœ… Conclusion

**All message types are now properly handled:**
- âœ… `token_chunk` â†’ Real-time token display
- âœ… `semantic_chunk` â†’ Real-time word display
- âœ… `sequential_audio` â†’ Audio playback with complete metadata
- âœ… `chunked_streaming_complete` â†’ Statistics and flag reset

**All errors fixed:**
- âœ… No more TypeError
- âœ… No more "Unknown message type" warnings
- âœ… Sample rate displays correctly
- âœ… Multiple interactions work perfectly

**Result:** Complete ultra-low latency streaming with real-time feedback! ğŸ‰

