#!/bin/bash
# Voxtral + TTS Integrated Deployment Script for RunPod
# Complete setup and deployment with pre-loaded models

set -e

echo "========================================================================"
echo "üöÄ Voxtral + TTS Integrated Real-time Voice Application"
echo "========================================================================"
echo "üìã Features:"
echo "   ‚Ä¢ Real-time Speech-to-Text (Voxtral-Mini-3B-2507)"
echo "   ‚Ä¢ Intelligent Text Generation (LLM)"
echo "   ‚Ä¢ High-quality Text-to-Speech (Orpheus TTS)"
echo "   ‚Ä¢ Voice Activity Detection (VAD)"
echo "   ‚Ä¢ WebSocket-based real-time communication"
echo "   ‚Ä¢ Pre-loaded models for instant conversation"
echo ""

# Function to check if a command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to check service availability
check_service() {
    local port=$1
    local service_name=$2
    local max_attempts=${3:-10}
    local attempt=1
    
    echo "üîç Checking $service_name on port $port..."
    
    while [ $attempt -le $max_attempts ]; do
        if nc -z localhost $port 2>/dev/null; then
            echo "‚úÖ $service_name is running on port $port"
            return 0
        fi
        
        echo "‚è≥ Attempt $attempt/$max_attempts - waiting for $service_name..."
        sleep 3
        attempt=$((attempt + 1))
    done
    
    echo "‚ùå $service_name failed to start on port $port after $max_attempts attempts"
    return 1
}

# Clean up any existing processes
cleanup_processes() {
    echo "üßπ Cleaning up existing processes..."
    
    # Kill processes on our ports
    for port in 8000 8005 8766; do
        if lsof -ti:$port >/dev/null 2>&1; then
            echo "üîÑ Stopping process on port $port..."
            lsof -ti:$port | xargs kill -9 2>/dev/null || true
        fi
    done
    
    # Kill any Python processes related to our application
    pkill -f "ui_server_realtime" 2>/dev/null || true
    pkill -f "health_check" 2>/dev/null || true
    pkill -f "tcp_server" 2>/dev/null || true
    
    sleep 2
    echo "‚úÖ Cleanup completed"
}

# Set up environment variables
setup_environment() {
    echo "üîß Setting up environment variables..."
    
    export CUDA_VISIBLE_DEVICES=0
    export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024
    export OMP_NUM_THREADS=8
    export TOKENIZERS_PARALLELISM=false
    export TORCH_COMPILE_DEBUG=0
    export PYTHONPATH="${PYTHONPATH}:$(pwd)"
    
    echo "‚úÖ Environment variables configured"
}

# Install system dependencies
install_system_deps() {
    echo "üì¶ Installing system dependencies..."
    
    # Update package list
    apt-get update -qq
    
    # Install essential packages
    apt-get install -y -qq \
        build-essential \
        cmake \
        git \
        wget \
        curl \
        unzip \
        netcat-openbsd \
        lsof \
        htop \
        ffmpeg \
        portaudio19-dev \
        python3-dev \
        espeak-ng \
        espeak-ng-data
    
    echo "‚úÖ System dependencies installed"
}

# Install Python dependencies
install_python_deps() {
    echo "üêç Installing Python dependencies..."
    
    # Upgrade pip
    pip install --upgrade pip setuptools wheel
    
    # Install PyTorch with CUDA support
    echo "‚ö° Installing PyTorch with CUDA support..."
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    
    # Install other requirements
    echo "üìö Installing application requirements..."
    pip install -r requirements.txt
    
    echo "‚úÖ Python dependencies installed"
}

# Download and cache models
cache_models() {
    echo "ü§ñ Downloading and caching models..."
    
    # Create model cache directory
    mkdir -p /workspace/model_cache
    
    # Cache Voxtral model
    echo "üì• Caching Voxtral model (this may take several minutes)..."
    python3 -c "
import torch
from transformers import VoxtralForConditionalGeneration, AutoProcessor

model_name = 'mistralai/Voxtral-Mini-3B-2507'
cache_dir = '/workspace/model_cache'

print('üì• Loading AutoProcessor...')
processor = AutoProcessor.from_pretrained(model_name, cache_dir=cache_dir)
print('‚úÖ AutoProcessor cached successfully')

print('üì• Loading Voxtral model...')
model = VoxtralForConditionalGeneration.from_pretrained(
    model_name, 
    cache_dir=cache_dir,
    torch_dtype=torch.bfloat16,
    device_map='auto',
    attn_implementation='eager',
    low_cpu_mem_usage=True,
    trust_remote_code=True
)
print('‚úÖ Voxtral model cached successfully')
"
    
    # Cache SNAC model for TTS
    echo "üì• Caching SNAC TTS model..."
    python3 -c "
from snac import SNAC
print('üì• Loading SNAC model...')
model = SNAC.from_pretrained('hubertsiuzdak/snac_24khz')
print('‚úÖ SNAC model cached successfully')
"
    
    echo "‚úÖ All models cached successfully"
}

# Start services
start_services() {
    echo "üöÄ Starting integrated services..."
    
    # Start health check server
    echo "ü©∫ Starting health check server on port 8005..."
    python -m src.api.health_check &
    HEALTH_PID=$!
    sleep 3
    
    # Start main UI server with integrated TTS
    echo "üåê Starting Voxtral + TTS UI Server on port 8000..."
    echo "üìã Features: STT + LLM + TTS + VAD + WebSocket streaming"
    python -m src.api.ui_server_realtime &
    UI_PID=$!
    sleep 8
    
    # Start TCP streaming server
    echo "üîó Starting TCP streaming server on port 8766..."
    python -m src.streaming.tcp_server &
    TCP_PID=$!
    sleep 5
    
    # Store PIDs for cleanup
    echo "$HEALTH_PID $UI_PID $TCP_PID" > /tmp/voxtral_pids.txt
    
    echo "‚úÖ All services started"
}

# Verify services
verify_services() {
    echo ""
    echo "üîç Verifying service startup..."
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    
    # Install netcat if not available
    if ! command_exists nc; then
        echo "üì¶ Installing netcat..."
        apt-get install -y netcat-openbsd
    fi
    
    # Check each service
    check_service 8005 "Health Check Server" 5
    check_service 8000 "Voxtral + TTS UI Server" 10
    check_service 8766 "TCP Streaming Server" 8
    
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    echo ""
    
    # Final verification
    services_running=true
    for port in 8005 8000 8766; do
        if ! nc -z localhost $port 2>/dev/null; then
            services_running=false
            echo "‚ùå Service on port $port is not responding"
            break
        fi
    done
    
    if [ "$services_running" = true ]; then
        echo "üéâ ALL SERVICES RUNNING SUCCESSFULLY!"
        return 0
    else
        echo "‚ùå Some services failed to start"
        return 1
    fi
}

# Display final information
show_completion_info() {
    echo ""
    echo "üéâ VOXTRAL + TTS DEPLOYMENT COMPLETE!"
    echo "========================================================================"
    echo ""
    echo "üåê Access URLs (replace [POD_ID] with your RunPod ID):"
    echo "   ‚Ä¢ Web Interface: https://[POD_ID]-8000.proxy.runpod.net"
    echo "   ‚Ä¢ Health Check:  https://[POD_ID]-8005.proxy.runpod.net/health"
    echo "   ‚Ä¢ WebSocket:     wss://[POD_ID]-8000.proxy.runpod.net/ws"
    echo ""
    echo "üéØ How to Use:"
    echo "   1. Open the Web Interface in your browser"
    echo "   2. Click 'Connect' to establish WebSocket connection"
    echo "   3. Click 'Start Conversation' to begin real-time interaction"
    echo "   4. Speak into your microphone"
    echo "   5. Receive AI text responses AND audio responses"
    echo ""
    echo "üîß Features Enabled:"
    echo "   ‚úÖ Real-time Speech-to-Text (Voxtral)"
    echo "   ‚úÖ Intelligent Text Generation"
    echo "   ‚úÖ High-quality Text-to-Speech (Orpheus)"
    echo "   ‚úÖ Voice Activity Detection"
    echo "   ‚úÖ Pre-loaded models (no startup delay)"
    echo "   ‚úÖ WebSocket streaming"
    echo ""
    echo "üìä Performance:"
    echo "   ‚Ä¢ Models pre-loaded at startup"
    echo "   ‚Ä¢ GPU-optimized processing"
    echo "   ‚Ä¢ <200ms latency target"
    echo "   ‚Ä¢ Real-time audio streaming"
    echo ""
    echo "üõë To stop services: pkill -f 'src.api' && pkill -f 'src.streaming'"
    echo "========================================================================"
}

# Main deployment function
main() {
    echo "Starting deployment process..."
    
    cleanup_processes
    setup_environment
    install_system_deps
    install_python_deps
    cache_models
    start_services
    
    if verify_services; then
        show_completion_info
        
        # Keep the script running to maintain services
        echo ""
        echo "üîÑ Services are running. Press Ctrl+C to stop all services."
        echo ""
        
        # Wait for interrupt
        trap 'echo ""; echo "üõë Stopping services..."; cleanup_processes; exit 0' INT
        while true; do
            sleep 10
            # Check if services are still running
            if ! nc -z localhost 8000 2>/dev/null; then
                echo "‚ùå Main service stopped unexpectedly"
                break
            fi
        done
    else
        echo "‚ùå Deployment failed - some services could not start"
        cleanup_processes
        exit 1
    fi
}

# Run main function
main "$@"
